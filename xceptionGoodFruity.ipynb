{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mary-ts/Neural-Computing/blob/main/xceptionGoodFruity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVhvb2zpFJjj"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP5Qk3nRrJ8W",
        "outputId": "bf1c25e5-990b-4cc9-9d6c-e43ac92557c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0UtFlsCx3p7v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras.layers as layers\n",
        "from keras import Sequential\n",
        "import keras.models\n",
        "from keras.layers import *\n",
        "from keras.models import * \n",
        "from keras import optimizers, applications\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkKj_nmXFMVx"
      },
      "source": [
        "Dataset Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wLUXspsC3r59"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/CNN IMAGES/archive (1)/val/train\"\n",
        "test_path = \"/content/drive/MyDrive/CNN IMAGES/archive (1)/val/val\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3FzUSSnFPBX"
      },
      "source": [
        "Creating training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2BnRGnO1_Gid"
      },
      "outputs": [],
      "source": [
        "train_datagen = image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "test_datagen= image.ImageDataGenerator(    \n",
        "    rotation_range=15,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "# Split with a ratio.\n",
        "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
        "splitfolders.ratio(\"/content/drive/MyDrive/CNN IMAGES/archive (1)/train/train\", output=\"/content/drive/MyDrive/CNN IMAGES/archive (1)/val\",\n",
        "    seed=1337, ratio=(.8, .2), group_prefix=None, move=False) # default values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM5vjm2bzWzB",
        "outputId": "05f61691-1cc4-4cd2-acf8-7020fd5f0edc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 16854 files [05:50, 48.09 files/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLIPKlW7FT4b"
      },
      "source": [
        "Importing data into generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohGl3H5QC1KJ",
        "outputId": "3f73c3b0-01fa-43ad-b006-c24bf96f2fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13471 images belonging to 33 classes.\n",
            "Found 3383 images belonging to 33 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size = (299,299),\n",
        "    batch_size = 8,\n",
        "    class_mode = 'categorical', \n",
        "    shuffle=True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size = (299,299),\n",
        "    batch_size = 8,\n",
        "    shuffle=True,\n",
        "    class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx24OGvzOMqY"
      },
      "source": [
        "Xception Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvYME2sPOLnB",
        "outputId": "206563f1-62b8-40fb-ae64-d3d684880b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model = applications.Xception(weights='imagenet', \n",
        "                              include_top=False, \n",
        "                              input_shape=(299, 299, 3))\n",
        "\n",
        "for layer in model.layers[:-5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(.3)(x)\n",
        "predictions = Dense(33, activation=\"softmax\")(x)\n",
        "model_final = Model(model.input, predictions)\n",
        "\n",
        "model_final.compile(optimizers.RMSprop(learning_rate=0.0001, decay=1e-5),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#model_final.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qdDU9-qQfp6"
      },
      "source": [
        "Xception\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOmqg4EDQjRk",
        "outputId": "c7d4795c-d83a-46d4-84e0-46be746eee5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.81729, saving model to vgg16_1.h5\n",
            "150/150 - 56s - loss: 3.0566 - accuracy: 0.2625 - val_loss: 1.8173 - val_accuracy: 0.4500 - 56s/epoch - 376ms/step\n",
            "Epoch 2/25\n",
            "\n",
            "Epoch 2: val_loss improved from 1.81729 to 1.11587, saving model to vgg16_1.h5\n",
            "150/150 - 39s - loss: 1.7564 - accuracy: 0.5100 - val_loss: 1.1159 - val_accuracy: 0.6500 - 39s/epoch - 260ms/step\n",
            "Epoch 3/25\n",
            "\n",
            "Epoch 3: val_loss improved from 1.11587 to 0.88812, saving model to vgg16_1.h5\n",
            "150/150 - 40s - loss: 1.3223 - accuracy: 0.6155 - val_loss: 0.8881 - val_accuracy: 0.7875 - 40s/epoch - 266ms/step\n",
            "Epoch 4/25\n",
            "\n",
            "Epoch 4: val_loss improved from 0.88812 to 0.51309, saving model to vgg16_1.h5\n",
            "150/150 - 39s - loss: 0.9952 - accuracy: 0.6967 - val_loss: 0.5131 - val_accuracy: 0.8250 - 39s/epoch - 260ms/step\n",
            "Epoch 5/25\n",
            "\n",
            "Epoch 5: val_loss did not improve from 0.51309\n",
            "150/150 - 32s - loss: 0.9006 - accuracy: 0.7458 - val_loss: 0.6337 - val_accuracy: 0.7875 - 32s/epoch - 215ms/step\n",
            "Epoch 6/25\n",
            "\n",
            "Epoch 6: val_loss improved from 0.51309 to 0.23632, saving model to vgg16_1.h5\n",
            "150/150 - 39s - loss: 0.7277 - accuracy: 0.7925 - val_loss: 0.2363 - val_accuracy: 0.9125 - 39s/epoch - 258ms/step\n",
            "Epoch 7/25\n"
          ]
        }
      ],
      "source": [
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "#early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=7, verbose=2, mode='auto')\n",
        "hist = model_final.fit_generator(generator=train_generator,                   \n",
        "                                    steps_per_epoch=150,\n",
        "                                    validation_data=test_generator,                    \n",
        "                                    validation_steps=10,\n",
        "                                    epochs=25,\n",
        "                                    callbacks = [checkpoint],\n",
        "                                    verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrRU_VBtS3IH"
      },
      "source": [
        "Plot Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ac8fe9iS4af"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(hist.history[\"loss\"])\n",
        "plt.plot(hist.history[\"accuracy\"])\n",
        "#plt.plot(hist.history[\"val_loss\"])\n",
        "plt.plot(hist.history[\"val_accuracy\"])\n",
        "plt.legend([\"accuracy\", \"val_accuracy\"])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}